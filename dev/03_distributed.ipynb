{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SaveDistributedModelCallback(TrackerCallback):\n",
    "    \"SaveModelCallback modified for distributed transfer learning - remove torch.load\"\n",
    "    def __init__(self, learn:Learner, monitor:str='val_loss', mode:str='auto', every:str='improvement',\n",
    "                 name:str='bestmodel', best_init=None, gpu=None):\n",
    "        super().__init__(learn, monitor=monitor, mode=mode)\n",
    "        self.every,self.name = every,name\n",
    "        if self.every not in ['improvement', 'epoch']:\n",
    "            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n",
    "            self.every = 'improvement'\n",
    "        if best_init: self.best = best_init \n",
    "        self.gpu = gpu\n",
    "      \n",
    "    def on_train_begin(self, **kwargs:Any)->None:\n",
    "        \"Initializes the best value.\"\n",
    "        if not hasattr(self, 'best'):\n",
    "            self.best = float('inf') if self.operator == np.less else -float('inf')\n",
    "        \n",
    "    def jump_to_epoch(self, epoch:int)->None:\n",
    "        try: \n",
    "            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n",
    "            print(f\"Loaded {self.name}_{epoch-1}\")\n",
    "        except: print(f'Model {self.name}_{epoch-1} not found.')\n",
    "\n",
    "    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n",
    "        \"Compare the value monitored to its best score and maybe save the model.\"\n",
    "        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n",
    "        else: #every=\"improvement\"\n",
    "            current = self.get_monitor_value()\n",
    "            if current is not None and self.operator(current, self.best):\n",
    "                if not self.gpu: print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n",
    "                self.best = current\n",
    "                self.learn.save(f'{self.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 03_distributed.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(\"03_distributed.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
