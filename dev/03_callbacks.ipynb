{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from time import time\n",
    "from fastprogress.fastprogress import format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SaveDistributedModelCallback(TrackerCallback):\n",
    "    \"SaveModelCallback modified for distributed transfer learning - remove torch.load\"\n",
    "    def __init__(self, learn:Learner, monitor:str='val_loss', mode:str='auto', every:str='improvement',\n",
    "                 name:str='bestmodel', gpu=None):\n",
    "        super().__init__(learn, monitor=monitor, mode=mode)\n",
    "        self.every,self.name = every,name\n",
    "        if self.every not in ['improvement', 'epoch']:\n",
    "            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n",
    "            self.every = 'improvement'\n",
    "        self.gpu = gpu\n",
    "      \n",
    "    def on_train_begin(self, **kwargs:Any)->None:\n",
    "        \"Initializes the best value.\"\n",
    "        if not hasattr(self, 'best'):\n",
    "            print(\"Initializing self.best\")\n",
    "            self.best = float('inf') if self.operator == np.less else -float('inf')\n",
    "        \n",
    "    def jump_to_epoch(self, epoch:int)->None:\n",
    "        try: \n",
    "            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n",
    "            print(f\"Loaded {self.name}_{epoch-1}\")\n",
    "        except: print(f'Model {self.name}_{epoch-1} not found.')\n",
    "\n",
    "    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n",
    "        \"Compare the value monitored to its best score and maybe save the model.\"\n",
    "        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n",
    "        else: \n",
    "            current = self.get_monitor_value()\n",
    "            if current is not None and self.operator(current, self.best):\n",
    "                if not self.gpu: print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n",
    "                self.best = current\n",
    "                self.learn.save(f'{self.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CSVLogger(LearnerCallback):\n",
    "    \"A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.\"\n",
    "    def __init__(self, learn:Learner, filename: str = 'history', append: bool = False): \n",
    "        super().__init__(learn)\n",
    "        self.filename,self.path,self.append = filename,self.learn.path/f'{filename}.csv',append\n",
    "        self.add_time = True\n",
    "\n",
    "    def read_logged_file(self):  \n",
    "        \"Read the content of saved file\"\n",
    "        return pd.read_csv(self.path)\n",
    "\n",
    "    def on_train_begin(self, **kwargs: Any) -> None:\n",
    "        \"Prepare file with metric names.\"\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)      \n",
    "        self.file = self.path.open('a') if self.append else self.path.open('w')\n",
    "        self.file.write(','.join(self.learn.recorder.names[:(None if self.add_time else -1)]) + '\\n')\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs:Any)->None:\n",
    "        if self.add_time: self.start_epoch = time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch: int, smooth_loss: Tensor, last_metrics: MetricsList, **kwargs: Any) -> bool:\n",
    "        \"Add a line with `epoch` number, `smooth_loss` and `last_metrics`.\"\n",
    "        last_metrics = ifnone(last_metrics, [])\n",
    "        stats = [str(stat) if isinstance(stat, int) else '#na#' if stat is None else f'{stat:.6f}'\n",
    "                 for name, stat in zip(self.learn.recorder.names, [epoch, smooth_loss] + last_metrics)]\n",
    "        if self.add_time: stats.append(format_time(time() - self.start_epoch))\n",
    "        str_stats = ','.join(stats)\n",
    "        self.file.write(str_stats + '\\n')\n",
    "        self.file.flush()\n",
    "        os.fsync(self.file.fileno())\n",
    "\n",
    "    def on_train_end(self, **kwargs: Any) -> None:  \n",
    "        \"Close the file.\"\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.segmentation.dataset import SemanticSegmentationData\n",
    "from local.segmentation.metrics import *\n",
    "# test data creation\n",
    "PATH = Path(\"/home/turgutluk/.fastai/data/camvid\")\n",
    "IMAGES = \"images\"\n",
    "MASKS = \"labels\"\n",
    "CODES = \"codes.txt\"\n",
    "TRAIN, VALID, TEST = \"train.txt\", \"valid.txt\", \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size=None, bs=4, size=112)\n",
    "data = ssdata.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, models.resnet34); learn.metrics = [partial(foreground_acc, void_code=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_metric_name(f):\n",
    "    try: return f.func.__name__\n",
    "    except: return f.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cb = SaveDistributedModelCallback(learn, monitor=_get_metric_name(learn.metrics[0]))\n",
    "csvlog_cb = CSVLogger(learn, './history.csv', append=True)\n",
    "cbs = [save_cb, csvlog_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing self.best\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='67' class='' max='150', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      44.67% [67/150 00:06<00:08 1.5428]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cb.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(\"03_distributed.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
