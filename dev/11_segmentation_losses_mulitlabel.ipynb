{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp segmentation.losses_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.58.dev0\n"
     ]
    }
   ],
   "source": [
    "import fastai; print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *\n",
    "from local.segmentation.lovasz_loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = [\"lovasz_softmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "cross_entropy = CrossEntropyFlat(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 3]), torch.Size([1, 1, 3, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = torch.ones((1,2,3,3))\n",
    "\n",
    "_target = tensor([[[\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [0,1,1]\n",
    "]]])\n",
    "\n",
    "_input.size(), _target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_close(cross_entropy(_input, _target), tensor(0.6931), eps=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lovasz_softmax` -> (best:0, random:0.5, worst:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 3]), torch.Size([1, 1, 3, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = torch.ones((1,2,3,3))\n",
    "\n",
    "_input2 = tensor([[\n",
    "[\n",
    "    [1,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,0]\n",
    "],\n",
    "[\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [0,1,1]\n",
    "]\n",
    "]]).float()*1e3\n",
    "\n",
    "_input3 = tensor([[\n",
    "[\n",
    "    [1,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,0]\n",
    "],\n",
    "[\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [0,1,1]\n",
    "]\n",
    "]]).float()*-1e3\n",
    "\n",
    "_target = tensor([[[\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [0,1,1]\n",
    "]]])\n",
    "\n",
    "_input.size(), _target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random\n",
    "(lovasz_softmax(_input, _target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best\n",
    "(lovasz_softmax(_input2, _target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worst\n",
    "(lovasz_softmax(_input3, _target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `bce_sigmoid`\n",
    "\n",
    "Loss for **models that don't predict background** and use sigmoid + threshold instead of softmax/argmax. Useful for imbalanced class distributions, learning background is hard: see [Focal Loss](https://arxiv.org/pdf/1708.02002.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3, 3]), torch.Size([2, 1, 3, 3]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = torch.randn(2,4,3,3)\n",
    "# 0: void\n",
    "_target = tensor([\n",
    "    [[\n",
    "    [1,0,0],\n",
    "    [0,1,2],\n",
    "    [0,3,4]\n",
    "]],\n",
    "      [[\n",
    "    [1,0,0],\n",
    "    [0,1,2],\n",
    "    [0,3,4]\n",
    "]]\n",
    "\n",
    "])\n",
    "\n",
    "_input.size(), _target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bce_sigmoid(input, target, **bce_kwargs):\n",
    "    \"Background is not predict, e.g. codes.txt and background value in label image is 0\"\n",
    "    nclasses = input.size(1)\n",
    "    trange = tensor(np.arange(1, nclasses+1))[None,...,None,None].to(target.device)\n",
    "    new_target = target == trange\n",
    "    return F.binary_cross_entropy_with_logits(input, new_target.float(), **bce_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8397)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_sigmoid(_input, _target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_script.ipynb.\n",
      "Converted 02_scheduler.ipynb.\n",
      "Converted 03_callbacks.ipynb.\n",
      "Converted 10_segmentation_dataset.ipynb.\n",
      "Converted 11_segmentation_losses_mulitlabel.ipynb.\n",
      "Converted 11b_segmentation_losses_binary.ipynb.\n",
      "Converted 12_segmentation_metrics.ipynb.\n",
      "Converted 13_segmentation_models.ipynb.\n",
      "Converted segmentation_training.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
