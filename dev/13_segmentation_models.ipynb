{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp segmentation.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "1.0.58.dev0\n"
     ]
    }
   ],
   "source": [
    "%autosave 60 \n",
    "import fastai; print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.segmentation.dataset import SemanticSegmentationData\n",
    "from local.segmentation.metrics import *\n",
    "# from local.segmentation.losses_binary import *\n",
    "from local.segmentation.losses_multilabel import *\n",
    "# test data creation\n",
    "PATH = Path(\"/home/turgutluk/.fastai/data/camvid\")\n",
    "IMAGES = \"images\"\n",
    "MASKS = \"labels\"\n",
    "CODES = \"codes.txt\"\n",
    "TRAIN, VALID, TEST = \"train.txt\", \"valid.txt\", \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN,\n",
    "                                  VALID, TEST, sample_size=None, bs=4, size=112)\n",
    "data = ssdata.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "default_configs = {}\n",
    "model_funcs = {}\n",
    "splits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(name, data, config):\n",
    "    \"Get model given name, data and config. Undefined config is defaulted.\"\n",
    "    conf, copy_conf = default_configs[name].copy(), default_configs[name].copy()\n",
    "    conf.update(config)    \n",
    "    f = model_funcs[name]\n",
    "    model = f(data, conf)\n",
    "    split_fn = splits.get(name)\n",
    "    return model, split_fn, copy_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.learner import cnn_config\n",
    "\n",
    "_body_config = {\"pretrained\":True} \n",
    "_unet_config = {\"blur\":False, \"blur_final\":True, \"self_attention\":False,\n",
    "         \"y_range\":None, \"norm_type\":NormType, \"last_cross\":True, \"bottle\":False}\n",
    "dunet_config = {**_body_config, **_unet_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dunet_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ResDUnet [18,34,50,101,152]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.models import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "from fastai.vision.models.cadene_models import model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained': True,\n",
       " 'blur': False,\n",
       " 'blur_final': True,\n",
       " 'self_attention': False,\n",
       " 'y_range': None,\n",
       " 'norm_type': <enum 'NormType'>,\n",
       " 'last_cross': True,\n",
       " 'bottle': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunet_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_res_meta = model_meta[resnet18]\n",
    "_res_cut, _res_split = _res_meta['cut'], _res_meta['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _resdunet(arch, data, config):\n",
    "    \"Returns a resdunet model for a arch from data and final config\"\n",
    "    pretrained = config.pop(\"pretrained\")\n",
    "    try:    size = data.train_ds[0][0].size\n",
    "    except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "    body = create_body(arch, pretrained, _res_cut)\n",
    "    model = DynamicUnet(body, n_classes=data.c, img_size=size, **config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def resdunet18(data, config): return _resdunet(resnet18, data, config)\n",
    "model_funcs['resdunet18'] = resdunet18\n",
    "default_configs['resdunet18'] = dunet_config\n",
    "splits['resdunet18'] = _res_split\n",
    "\n",
    "def resdunet34(data, config): return _resdunet(resnet34, data, config)\n",
    "model_funcs['resdunet34'] = resdunet34\n",
    "default_configs['resdunet34'] = dunet_config\n",
    "splits['resdunet34'] = _res_split\n",
    "\n",
    "def resdunet50(data, config): return _resdunet(resnet50, data, config)\n",
    "model_funcs['resdunet50'] = resdunet50\n",
    "default_configs['resdunet50'] = dunet_config\n",
    "splits['resdunet50'] = _res_split\n",
    "\n",
    "def resdunet101(data, config): return _resdunet(resnet101, data, config)\n",
    "model_funcs['resdunet101'] = resdunet101\n",
    "default_configs['resdunet101'] = dunet_config\n",
    "splits['resdunet101'] = _res_split\n",
    "\n",
    "def resdunet152(data, config): return _resdunet(resnet152, data, config)\n",
    "model_funcs['resdunet152'] = resdunet152\n",
    "default_configs['resdunet152'] = dunet_config\n",
    "splits['resdunet152'] = _res_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, split_fn, config = get_model(name=\"resdunet50\", data=data, config={\"self_attention\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " {'pretrained': True,\n",
       "  'blur': False,\n",
       "  'blur_final': True,\n",
       "  'self_attention': False,\n",
       "  'y_range': None,\n",
       "  'norm_type': <enum 'NormType'>,\n",
       "  'last_cross': True,\n",
       "  'bottle': False})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_fn, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `DenseDUnet [121,161,169, 201]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from fastai.callbacks.hooks import model_sizes\n",
    "# from fastai.vision.models import densenet121, densenet161, densenet169, densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def _densedunet_split(m:nn.Module): return (m[0][3], m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# def _densedunet(arch, data, config):\n",
    "#     \"Returns a resdunet model for a arch from data and final config\"\n",
    "#     pretrained, cut = config.pop(\"pretrained\"), config.pop(\"cut\")\n",
    "#     body = create_body(arch, pretrained, cut)[0]\n",
    "#     densenet_children = list(body.children())\n",
    "#     new_body = nn.Sequential(nn.Sequential(*densenet_children[:4]),\n",
    "#                                nn.Sequential(*densenet_children[4:6]),\n",
    "#                                nn.Sequential(*densenet_children[6:8]),\n",
    "#                                nn.Sequential(*densenet_children[8:10]),\n",
    "#                                nn.Sequential(*densenet_children[10:]))\n",
    "#     try:    size = data.train_ds[0][0].size\n",
    "#     except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "#     model = DynamicUnet(new_body, n_classes=data.c, img_size=size, **config)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# def densedunet121(data, config): return _densedunet(densenet121, data, config)\n",
    "# model_funcs['densedunet121'] = densedunet121\n",
    "# default_configs['densedunet121'] = dunet_config\n",
    "# splits['densedunet121'] = _densedunet_split\n",
    "\n",
    "# def densedunet161(data, config): return _densedunet(densenet161, data, config)\n",
    "# model_funcs['densedunet161'] = densedunet161\n",
    "# default_configs['densedunet161'] = dunet_config\n",
    "# splits['densedunet161'] = _densedunet_split\n",
    "\n",
    "# def densedunet169(data, config): return _densedunet(densenet169, data, config)\n",
    "# model_funcs['densedunet169'] = densedunet169\n",
    "# default_configs['densedunet169'] = dunet_config\n",
    "# splits['densedunet169'] = _densedunet_split\n",
    "\n",
    "# def densedunet201(data, config): return _densedunet(densenet201, data, config)\n",
    "# model_funcs['densedunet201'] = densedunet201\n",
    "# default_configs['densedunet201'] = dunet_config\n",
    "# splits['densedunet201'] = _densedunet_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SE-ResDUneXt [50,101]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.models.cadene_models import se_resnext50_32x4d, se_resnext101_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_se_meta = model_meta[se_resnext50_32x4d]\n",
    "_se_cut, _se_split = _se_meta['cut'], _se_meta['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _seresdunext(arch, data, config):\n",
    "    \"Returns a resdunet model for a arch from data and final config\"\n",
    "    pretrained = config.pop(\"pretrained\")\n",
    "    try:    size = data.train_ds[0][0].size\n",
    "    except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "    body = create_body(arch, pretrained, cut=_se_cut)\n",
    "    model = DynamicUnet(body, n_classes=data.c, img_size=size, **config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seresdunext50(data, config): return _seresdunext(se_resnext50_32x4d, data, config)\n",
    "model_funcs['seresdunext50'] = seresdunext50\n",
    "default_configs['seresdunext50'] = dunet_config\n",
    "splits['seresdunext50'] = _se_split\n",
    "\n",
    "def seresdunext101(data, config): return _seresdunext(se_resnext101_32x4d, data, config)\n",
    "model_funcs['seresdunext101'] = seresdunext101\n",
    "default_configs['seresdunext101'] = dunet_config\n",
    "splits['seresdunext101'] = _se_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, split_fn, config = get_model(name=\"seresdunext50\", data=data, config={\"self_attention\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function fastai.vision.models.cadene_models.<lambda>(m)>,\n",
       " {'pretrained': True,\n",
       "  'blur': False,\n",
       "  'blur_final': True,\n",
       "  'self_attention': False,\n",
       "  'y_range': None,\n",
       "  'norm_type': <enum 'NormType'>,\n",
       "  'last_cross': True,\n",
       "  'bottle': False})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_fn, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DeepLab v3+ [ResNet50, ResNet101]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yelanlan/Pneumothorax-Segmentation-2nd-place-solution/blob/bf99230deffdd813fe730ddeaed6822ba37193df/semantic_segmentation/network/deepv3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_body_config = {\"pretrained\":True} \n",
    "_deeplab_config = {'variant':'D', 'skip':'m1', 'skip_num':48}\n",
    "deeplab_config = {**_body_config, **_deeplab_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _AtrousSpatialPyramidPoolingModule(nn.Module):\n",
    "    \"\"\"\n",
    "    operations performed:\n",
    "      1x1 x depth\n",
    "      3x3 x depth dilation 6\n",
    "      3x3 x depth dilation 12\n",
    "      3x3 x depth dilation 18\n",
    "      image pooling\n",
    "      concatenate all together\n",
    "      Final 1x1 conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dim, reduction_dim=256, output_stride=16, rates=(6, 12, 18)):\n",
    "        super(_AtrousSpatialPyramidPoolingModule, self).__init__()\n",
    "\n",
    "        # Check if we are using distributed BN and use the nn from encoding.nn\n",
    "        # library rather than using standard pytorch.nn\n",
    "\n",
    "        if output_stride == 8:\n",
    "            rates = [2 * r for r in rates]\n",
    "        elif output_stride == 16:\n",
    "            pass\n",
    "        else:\n",
    "            raise 'output stride of {} not supported'.format(output_stride)\n",
    "\n",
    "        self.features = []\n",
    "        # 1x1\n",
    "        self.features.append(\n",
    "            nn.Sequential(nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "                          nn.BatchNorm2d(reduction_dim), nn.ReLU(inplace=True)))\n",
    "        # other rates\n",
    "        for r in rates:\n",
    "            self.features.append(nn.Sequential(\n",
    "                nn.Conv2d(in_dim, reduction_dim, kernel_size=3,\n",
    "                          dilation=r, padding=r, bias=False),\n",
    "                nn.BatchNorm2d(reduction_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.features = torch.nn.ModuleList(self.features)\n",
    "\n",
    "        # img level features\n",
    "        self.img_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.img_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(reduction_dim), nn.ReLU(inplace=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "\n",
    "        img_features = self.img_pooling(x)\n",
    "        img_features = self.img_conv(img_features)\n",
    "        img_features = Upsample(img_features, x_size[2:])\n",
    "        out = img_features\n",
    "\n",
    "        for f in self.features:\n",
    "            y = f(x)\n",
    "            out = torch.cat((out, y), 1)\n",
    "        return out\n",
    "    \n",
    "def _Upsample(x, size):\n",
    "    \"\"\"\n",
    "    Wrapper Around the Upsample Call\n",
    "    \"\"\"\n",
    "    return nn.functional.interpolate(x, size=size, mode='bilinear', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _DeepV3Plus(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement DeepLab-V3 model\n",
    "    A: stride8\n",
    "    B: stride16\n",
    "    with skip connections\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, backbone='seresnext-50', pretrained=True, variant='D', \n",
    "                 skip='m1', skip_num=48):\n",
    "        super(_DeepV3Plus, self).__init__()\n",
    "        \n",
    "        self.variant, self.skip, self.skip_num = variant, skip, skip_num\n",
    "        \n",
    "        if backbone == 'seresnext50':\n",
    "            body = create_body(se_resnext50_32x4d, pretrained)\n",
    "        elif backbone == 'seresnext101':\n",
    "            body = create_body(se_resnext101_32x4d, pretrained)\n",
    "        elif backbone == 'resnet50':\n",
    "            body = create_body(resnet50, pretrained)\n",
    "            body = nn.Sequential(nn.Sequential(body[:4]), *body[4:])\n",
    "        elif backbone == 'resnet101':\n",
    "            body = create_body(resnet101, pretrained)\n",
    "            body = nn.Sequential(nn.Sequential(body[:4]), *body[4:])\n",
    "        else:\n",
    "            raise ValueError(\"Not a valid network arch\")\n",
    "            \n",
    "        self.body = body\n",
    "\n",
    "        if self.variant == 'D':\n",
    "            for n, m in self.body[3].named_modules():\n",
    "                if 'conv2' in n:\n",
    "                    m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "                elif 'downsample.0' in n:\n",
    "                    m.stride = (1, 1)\n",
    "            for n, m in self.body[4].named_modules():\n",
    "                if 'conv2' in n:\n",
    "                    m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "                elif 'downsample.0' in n:\n",
    "                    m.stride = (1, 1)\n",
    "        elif self.variant == 'D16':\n",
    "            for n, m in self.body[4].named_modules():\n",
    "                if 'conv2' in n:\n",
    "                    m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "                elif 'downsample.0' in n:\n",
    "                    m.stride = (1, 1)\n",
    "        else:\n",
    "            # raise 'unknown deepv3 variant: {}'.format(self.variant)\n",
    "            print(\"Not using Dilation \")\n",
    "\n",
    "        self.aspp = _AtrousSpatialPyramidPoolingModule(2048, 256, output_stride=8)\n",
    "\n",
    "        if self.skip == 'm1':\n",
    "            self.bot_fine = nn.Conv2d(256, self.skip_num, kernel_size=1, bias=False)\n",
    "        elif self.skip == 'm2':\n",
    "            self.bot_fine = nn.Conv2d(512, self.skip_num, kernel_size=1, bias=False)\n",
    "        else:\n",
    "            raise Exception('Not a valid skip')\n",
    "\n",
    "        self.bot_aspp = nn.Conv2d(1280, 256, kernel_size=1, bias=False)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(256 + self.skip_num, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1, bias=False))\n",
    "        \n",
    "        # init weights and biases\n",
    "        for m in [self.aspp, self.bot_aspp, self.bot_fine, self.final]:\n",
    "            apply_init(m, nn.init.kaiming_normal_)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, gts=None):\n",
    "\n",
    "        x_size = x.size()  # 800\n",
    "        x0 = self.body[0](x)  # 400\n",
    "        x1 = self.body[1](x0)  # 400\n",
    "        x2 = self.body[2](x1)  # 100\n",
    "        x3 = self.body[3](x2)  # 100\n",
    "        x4 = self.body[4](x3)  # 100\n",
    "        xp = self.aspp(x4)\n",
    "\n",
    "        dec0_up = self.bot_aspp(xp)\n",
    "        if self.skip == 'm1':\n",
    "            dec0_fine = self.bot_fine(x1)\n",
    "            dec0_up = Upsample(dec0_up, x1.size()[2:])\n",
    "        else:\n",
    "            dec0_fine = self.bot_fine(x2)\n",
    "            dec0_up = Upsample(dec0_up, x2.size()[2:])\n",
    "\n",
    "        dec0 = [dec0_fine, dec0_up]\n",
    "        dec0 = torch.cat(dec0, 1)\n",
    "        dec1 = self.final(dec0)\n",
    "        main_out = _Upsample(dec1, x_size[2:])\n",
    "        \n",
    "        return main_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _deeplabv3(arch_name, data, config):\n",
    "    \"Returns a resdunet model for a arch from data and final config\"\n",
    "    pretrained = config.pop(\"pretrained\")\n",
    "    model = _DeepV3Plus(data.c, arch_name, pretrained=pretrained, **config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _deeplab_split(m:nn.Module): return (m.body[3], m.aspp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def deeplabv3res50(data, config): return _deeplabv3(\"resnet50\", data, config)\n",
    "model_funcs['deeplabv3res50'] = deeplabv3res50\n",
    "default_configs['deeplabv3res50'] = deeplab_config\n",
    "splits['deeplabv3res50'] = _deeplab_split\n",
    "\n",
    "def deeplabv3res101(data, config): return _deeplabv3(\"resnet101\", data, config)\n",
    "model_funcs['deeplabv3res101'] = deeplabv3res101\n",
    "default_configs['deeplabv3res101'] = deeplab_config\n",
    "splits['deeplabv3res101'] = _deeplab_split\n",
    "\n",
    "def deeplabv3seresnext50(data, config): return _deeplabv3(\"seresnext50\", data, config)\n",
    "model_funcs['deeplabv3seresnext50'] = deeplabv3seresnext50\n",
    "default_configs['deeplabv3seresnext50'] = deeplab_config\n",
    "splits['deeplabv3seresnext50'] = _deeplab_split\n",
    "\n",
    "def deeplabv3seresnext101(data, config): return _deeplabv3(\"seresnext101\", data, config)\n",
    "model_funcs['deeplabv3seresnext101'] = deeplabv3seresnext101\n",
    "default_configs['deeplabv3seresnext101'] = deeplab_config\n",
    "splits['deeplabv3seresnext101'] = _deeplab_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, split_fn, config = get_model(name=\"deeplabv3res50\", data=data, config={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__._deeplab_split(m: torch.nn.modules.module.Module)>,\n",
       " {'pretrained': True, 'variant': 'D', 'skip': 'm1', 'skip_num': 48})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_fn, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resdunet18': <function __main__.resdunet18(data, config)>,\n",
       " 'resdunet34': <function __main__.resdunet34(data, config)>,\n",
       " 'resdunet50': <function __main__.resdunet50(data, config)>,\n",
       " 'resdunet101': <function __main__.resdunet101(data, config)>,\n",
       " 'resdunet152': <function __main__.resdunet152(data, config)>,\n",
       " 'seresdunext50': <function __main__.seresdunext50(data, config)>,\n",
       " 'seresdunext101': <function __main__.seresdunext101(data, config)>,\n",
       " 'deeplabv3res50': <function __main__.deeplabv3res50(data, config)>,\n",
       " 'deeplabv3res101': <function __main__.deeplabv3res101(data, config)>,\n",
       " 'deeplabv3seresnext50': <function __main__.deeplabv3seresnext50(data, config)>,\n",
       " 'deeplabv3seresnext101': <function __main__.deeplabv3seresnext101(data, config)>}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resdunet18': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet34': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet50': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet101': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet152': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'seresdunext50': <function fastai.vision.models.cadene_models.<lambda>(m)>,\n",
       " 'seresdunext101': <function fastai.vision.models.cadene_models.<lambda>(m)>,\n",
       " 'deeplabv3res50': <function __main__._deeplab_split(m: torch.nn.modules.module.Module)>,\n",
       " 'deeplabv3res101': <function __main__._deeplab_split(m: torch.nn.modules.module.Module)>,\n",
       " 'deeplabv3seresnext50': <function __main__._deeplab_split(m: torch.nn.modules.module.Module)>,\n",
       " 'deeplabv3seresnext101': <function __main__._deeplab_split(m: torch.nn.modules.module.Module)>}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `resdunet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:48 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>323.644714</td>\n",
       "      <td>442.502716</td>\n",
       "      <td>0.163323</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.906981</td>\n",
       "      <td>1.347440</td>\n",
       "      <td>0.591348</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.761052</td>\n",
       "      <td>1.076236</td>\n",
       "      <td>0.607597</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 01:52 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.026368</td>\n",
       "      <td>0.954200</td>\n",
       "      <td>0.693545</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.858912</td>\n",
       "      <td>0.751986</td>\n",
       "      <td>0.785202</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.734937</td>\n",
       "      <td>0.629576</td>\n",
       "      <td>0.827223</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, split_fn, config = get_model(name=\"resdunet50\", data=data, config={\"self_attention\":False})\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "learn = learn.split(split_fn)\n",
    "if config.get(\"pretrained\"): learn.freeze()\n",
    "else: apply_init(learn.model, nn.init.kaiming_normal_)\n",
    "learn.fit_one_cycle(3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8272225260734558\n"
     ]
    }
   ],
   "source": [
    "res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "assert res > 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `densedunet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, split, config = get_model(name=\"densedunet161\", data=data, config={\"self_attention\":False})\n",
    "# learn = Learner(data, model)\n",
    "# learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "# learn = learn.split(split)\n",
    "# if config.get(\"pretrained\"): learn.freeze()\n",
    "# learn.fit_one_cycle(3)\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "# assert res > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `seresdunext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:13 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.222561</td>\n",
       "      <td>0.989750</td>\n",
       "      <td>0.711971</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.781840</td>\n",
       "      <td>0.668924</td>\n",
       "      <td>0.791899</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.639688</td>\n",
       "      <td>0.543867</td>\n",
       "      <td>0.841148</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 02:41 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.912261</td>\n",
       "      <td>1.415649</td>\n",
       "      <td>0.650521</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.799568</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697662</td>\n",
       "      <td>0.638540</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, split_fn, config = get_model(name=\"seresdunext50\", data=data, config={\"self_attention\":True})\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "learn = learn.split(split_fn)\n",
    "if config.get(\"pretrained\"): learn.freeze()\n",
    "learn.fit_one_cycle(3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015714883804321\n"
     ]
    }
   ],
   "source": [
    "res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "assert res > 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deeplabv3+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:49 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.066412</td>\n",
       "      <td>0.919670</td>\n",
       "      <td>0.775467</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.813698</td>\n",
       "      <td>0.693670</td>\n",
       "      <td>0.819726</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.712370</td>\n",
       "      <td>0.659535</td>\n",
       "      <td>0.824959</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:56 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.635908</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659343</td>\n",
       "      <td>0.583498</td>\n",
       "      <td>0.831742</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.571845</td>\n",
       "      <td>0.499947</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, split_fn, config = get_model(name=\"deeplabv3res50\", data=data, config={})\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "learn = learn.split(split_fn)\n",
    "if config.get(\"pretrained\"): learn.freeze()\n",
    "learn.fit_one_cycle(3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8615361452102661\n"
     ]
    }
   ],
   "source": [
    "res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "assert res > 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_script.ipynb.\n",
      "Converted 02_scheduler.ipynb.\n",
      "Converted 03_callbacks.ipynb.\n",
      "Converted 10_segmentation_dataset.ipynb.\n",
      "Converted 11_segmentation_losses_mulitlabel.ipynb.\n",
      "Converted 11b_segmentation_losses_binary.ipynb.\n",
      "Converted 12_segmentation_metrics.ipynb.\n",
      "Converted 13_segmentation_models.ipynb.\n",
      "Converted segmentation_training.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
