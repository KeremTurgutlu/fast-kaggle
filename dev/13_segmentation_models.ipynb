{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp segmentation.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "1.0.58.dev0\n"
     ]
    }
   ],
   "source": [
    "%autosave 60 \n",
    "import fastai; print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.segmentation.dataset import SemanticSegmentationData\n",
    "from local.segmentation.metrics import *\n",
    "# from local.segmentation.losses_binary import *\n",
    "from local.segmentation.losses_multilabel import *\n",
    "# test data creation\n",
    "PATH = Path(\"/home/turgutluk/.fastai/data/camvid\")\n",
    "IMAGES = \"images\"\n",
    "MASKS = \"labels\"\n",
    "CODES = \"codes.txt\"\n",
    "TRAIN, VALID, TEST = \"train.txt\", \"valid.txt\", \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN,\n",
    "                                  VALID, TEST, sample_size=None, bs=4, size=112)\n",
    "data = ssdata.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "default_configs = {}\n",
    "model_funcs = {}\n",
    "splits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(name, data, config):\n",
    "    \"Get model given name, data and config. Undefined config is defaulted.\"\n",
    "    conf, copy_conf = default_configs[name].copy(), default_configs[name].copy()\n",
    "    conf.update(config)    \n",
    "    f = model_funcs[name]\n",
    "    model = f(data, conf)\n",
    "    split = splits.get(name)\n",
    "    return model, split, copy_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export - dynamic unet config\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.learner import cnn_config\n",
    "\n",
    "body_config = {\"pretrained\":True, \"cut\":None} \n",
    "unet_config = {\"blur\":False, \"blur_final\":True, \"self_attention\":False,\n",
    "         \"y_range\":None, \"norm_type\":NormType, \"last_cross\":True, \"bottle\":False}\n",
    "dunet_config = {**body_config, **unet_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ResDUnet [18,34,50,101,152]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.models import resnet18, resnet34, resnet50, resnet101, resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained': True,\n",
       " 'cut': None,\n",
       " 'blur': False,\n",
       " 'blur_final': True,\n",
       " 'self_attention': False,\n",
       " 'y_range': None,\n",
       " 'norm_type': <enum 'NormType'>,\n",
       " 'last_cross': True,\n",
       " 'bottle': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunet_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _resdunet(arch, data, config):\n",
    "    \"Returns a resdunet model for a arch from data and final config\"\n",
    "    pretrained, cut = config.pop(\"pretrained\"), config.pop(\"cut\")\n",
    "    try:    size = data.train_ds[0][0].size\n",
    "    except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "    body = create_body(arch, pretrained, cut)\n",
    "    model = DynamicUnet(body, n_classes=data.c, img_size=size, **config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def resdunet18(data, config): return _resdunet(resnet18, data, config)\n",
    "model_funcs['resdunet18'] = resdunet18\n",
    "default_configs['resdunet18'] = dunet_config\n",
    "splits['resdunet18'] = cnn_config(resnet18)['split']\n",
    "\n",
    "def resdunet34(data, config): return _resdunet(resnet34, data, config)\n",
    "model_funcs['resdunet34'] = resdunet34\n",
    "default_configs['resdunet34'] = dunet_config\n",
    "splits['resdunet34'] = cnn_config(resnet34)['split']\n",
    "\n",
    "def resdunet50(data, config): return _resdunet(resnet50, data, config)\n",
    "model_funcs['resdunet50'] = resdunet50\n",
    "default_configs['resdunet50'] = dunet_config\n",
    "splits['resdunet50'] = cnn_config(resnet50)['split']\n",
    "\n",
    "def resdunet101(data, config): return _resdunet(resnet101, data, config)\n",
    "model_funcs['resdunet101'] = resdunet101\n",
    "default_configs['resdunet101'] = dunet_config\n",
    "splits['resdunet101'] = cnn_config(resnet101)['split']\n",
    "\n",
    "def resdunet152(data, config): return _resdunet(resnet152, data, config)\n",
    "model_funcs['resdunet152'] = resdunet152\n",
    "default_configs['resdunet152'] = dunet_config\n",
    "splits['resdunet152'] = cnn_config(resnet152)['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, split,_ = get_model(name=\"resdunet50\", data=data, config={\"self_attention\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `DenseDUnet [121,161,169, 201]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from fastai.callbacks.hooks import model_sizes\n",
    "# from fastai.vision.models import densenet121, densenet161, densenet169, densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def _densedunet_split(m:nn.Module): return (m[0][3], m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# def _densedunet(arch, data, config):\n",
    "#     \"Returns a resdunet model for a arch from data and final config\"\n",
    "#     pretrained, cut = config.pop(\"pretrained\"), config.pop(\"cut\")\n",
    "#     body = create_body(arch, pretrained, cut)[0]\n",
    "#     densenet_children = list(body.children())\n",
    "#     new_body = nn.Sequential(nn.Sequential(*densenet_children[:4]),\n",
    "#                                nn.Sequential(*densenet_children[4:6]),\n",
    "#                                nn.Sequential(*densenet_children[6:8]),\n",
    "#                                nn.Sequential(*densenet_children[8:10]),\n",
    "#                                nn.Sequential(*densenet_children[10:]))\n",
    "#     try:    size = data.train_ds[0][0].size\n",
    "#     except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "#     model = DynamicUnet(new_body, n_classes=data.c, img_size=size, **config)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #export\n",
    "# def densedunet121(data, config): return _densedunet(densenet121, data, config)\n",
    "# model_funcs['densedunet121'] = densedunet121\n",
    "# default_configs['densedunet121'] = dunet_config\n",
    "# splits['densedunet121'] = _densedunet_split\n",
    "\n",
    "# def densedunet161(data, config): return _densedunet(densenet161, data, config)\n",
    "# model_funcs['densedunet161'] = densedunet161\n",
    "# default_configs['densedunet161'] = dunet_config\n",
    "# splits['densedunet161'] = _densedunet_split\n",
    "\n",
    "# def densedunet169(data, config): return _densedunet(densenet169, data, config)\n",
    "# model_funcs['densedunet169'] = densedunet169\n",
    "# default_configs['densedunet169'] = dunet_config\n",
    "# splits['densedunet169'] = _densedunet_split\n",
    "\n",
    "# def densedunet201(data, config): return _densedunet(densenet201, data, config)\n",
    "# model_funcs['densedunet201'] = densedunet201\n",
    "# default_configs['densedunet201'] = dunet_config\n",
    "# splits['densedunet201'] = _densedunet_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SE-ResDUneXt [50,101]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.models.cadene_models import se_resnext50_32x4d, se_resnext101_32x4d\n",
    "from fastai.vision.models.cadene_models import model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_se_meta = model_meta[se_resnext50_32x4d]\n",
    "_se_cut, _se_split = _se_meta['cut'], _se_meta['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _seresdunext(arch, data, config):\n",
    "    \"Returns a resdunet model for a arch from data and final config\"\n",
    "    pretrained, cut = config.pop(\"pretrained\"), config.pop(\"cut\")\n",
    "    try:    size = data.train_ds[0][0].size\n",
    "    except: size = next(iter(data.train_dl))[0].shape[-2:]\n",
    "    body = create_body(arch, pretrained, cut=_se_cut)\n",
    "    model = DynamicUnet(body, n_classes=data.c, img_size=size, **config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def seresdunext50(data, config): return _seresdunext(se_resnext50_32x4d, data, config)\n",
    "model_funcs['seresdunext50'] = seresdunext50\n",
    "default_configs['seresdunext50'] = dunet_config\n",
    "splits['seresdunext50'] = _se_split\n",
    "\n",
    "def seresdunext101(data, config): return _seresdunext(se_resnext101_32x4d, data, config)\n",
    "model_funcs['seresdunext101'] = seresdunext101\n",
    "default_configs['seresdunext101'] = dunet_config\n",
    "splits['seresdunext101'] = _se_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, split,_ = get_model(name=\"seresdunext50\", data=data, config={\"self_attention\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DeepLab v3+ [ResNet50, ResNet101]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeplabv3_resnet101(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/master.zip\" to /home/turgutluk/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'wide_resnet50_2' from 'torchvision.models.resnet' (/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/torchvision/models/resnet.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0c9b1292ca65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/vision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deeplabv3_resnet101'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/my_fastai/lib/python3.7/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(github, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mhub_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_fastai/lib/python3.7/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_fastai/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/my_fastai/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_vision_master/hubconf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdensenet121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet169\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensenet161\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet152\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresnext50_32x4d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnext101_32x8d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwide_resnet50_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwide_resnet101_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueezenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqueezenet1_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueezenet1_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'wide_resnet50_2' from 'torchvision.models.resnet' (/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/torchvision/models/resnet.py)"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'deeplabv3_resnet101', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `tests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from local.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resdunet18': <function __main__.resdunet18(data, config)>,\n",
       " 'resdunet34': <function __main__.resdunet34(data, config)>,\n",
       " 'resdunet50': <function __main__.resdunet50(data, config)>,\n",
       " 'resdunet101': <function __main__.resdunet101(data, config)>,\n",
       " 'resdunet152': <function __main__.resdunet152(data, config)>,\n",
       " 'densedunet121': <function __main__.densedunet121(data, config)>,\n",
       " 'densedunet161': <function __main__.densedunet161(data, config)>,\n",
       " 'densedunet169': <function __main__.densedunet169(data, config)>,\n",
       " 'densedunet201': <function __main__.densedunet201(data, config)>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resdunet18': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet34': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet50': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet101': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'resdunet152': <function fastai.vision.learner._resnet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'densedunet121': <function __main__._densedunet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'densedunet161': <function __main__._densedunet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'densedunet169': <function __main__._densedunet_split(m: torch.nn.modules.module.Module)>,\n",
       " 'densedunet201': <function __main__._densedunet_split(m: torch.nn.modules.module.Module)>}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `resdunet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:25 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.777493</td>\n",
       "      <td>2.456983</td>\n",
       "      <td>0.418664</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.364526</td>\n",
       "      <td>1.005066</td>\n",
       "      <td>0.716271</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.943640</td>\n",
       "      <td>0.756950</td>\n",
       "      <td>0.806386</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:26 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.832981</td>\n",
       "      <td>0.781028</td>\n",
       "      <td>0.807179</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761613</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.835867</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666020</td>\n",
       "      <td>0.550050</td>\n",
       "      <td>0.849063</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, split, config = get_model(name=\"resdunet18\", data=data, config={\"self_attention\":False})\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "learn = learn.split(split)\n",
    "if config.get(\"pretrained\"): learn.freeze()\n",
    "learn.fit_one_cycle(3)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490628004074097\n"
     ]
    }
   ],
   "source": [
    "res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "assert res > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `densedunet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model, split, config = get_model(name=\"densedunet161\", data=data, config={\"self_attention\":False})\n",
    "# learn = Learner(data, model)\n",
    "# learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "# learn = learn.split(split)\n",
    "# if config.get(\"pretrained\"): learn.freeze()\n",
    "# learn.fit_one_cycle(3)\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "# assert res > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `seresdunext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:06 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>foreground_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.945091</td>\n",
       "      <td>2.052992</td>\n",
       "      <td>0.463276</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.553678</td>\n",
       "      <td>1.263506</td>\n",
       "      <td>0.591455</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.070011</td>\n",
       "      <td>0.958146</td>\n",
       "      <td>0.662554</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, split, config = get_model(name=\"seresdunext50\", data=data, config={\"self_attention\":True})\n",
    "learn = Learner(data, model)\n",
    "learn.metrics = [partial(foreground_acc, void_code=31)]\n",
    "learn = learn.split(split)\n",
    "if config.get(\"pretrained\"): learn.freeze()\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8222544193267822\n"
     ]
    }
   ],
   "source": [
    "res = learn.recorder.metrics[-1][0].item(); print(res)\n",
    "assert res > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_script.ipynb.\n",
      "Converted 02_scheduler.ipynb.\n",
      "Converted 03_callbacks.ipynb.\n",
      "Converted 10_segmentation_dataset.ipynb.\n",
      "Converted 11_segmentation_losses_mulitlabel.ipynb.\n",
      "Converted 11b_segmentation_losses_binary.ipynb.\n",
      "Converted 12_segmentation_metrics.ipynb.\n",
      "Converted 13_segmentation_models.ipynb.\n",
      "Converted segmentation_training.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
