{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp classification.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai; print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class ImageClassificationData:\n",
    "    \"Creates image classification dataset from fastai datablock API\"\n",
    "    def __init__(self,PATH,IMAGES,LABELS,TRAIN,VALID,TEST,\n",
    "                 is_multilabel,sample_size,bs,size,**dl_kwargs):\n",
    "        # input params\n",
    "        self.path, self.sample_size, self.bs, self.size  = \\\n",
    "        PATH, sample_size, bs, size\n",
    "        self.label_cls = partial(MultiCategoryList, label_delim=\";\") if is_multilabel else CategoryList\n",
    "        self.VALID, self.TEST = VALID, TEST\n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        \n",
    "        # read training\n",
    "        self.train_df = pd.read_csv(self.path/TRAIN, header=None)        \n",
    "        if sample_size: self.train_df = self.train_df.sample(sample_size)\n",
    "    \n",
    "        # read validation and test\n",
    "        if (VALID is not None) and (type(VALID) is str): \n",
    "            self.valid_file = True\n",
    "        else:\n",
    "            self.valid_file = False\n",
    "        if self.valid_file: self.valid_df = pd.read_csv(self.path/VALID, header=None)\n",
    "        if TEST is not None: self.test_df = pd.read_csv(self.path/TEST, header=None)\n",
    "        \n",
    "        # read labels\n",
    "        self.labels_df = pd.read_csv(self.path/LABELS)\n",
    "        \n",
    "        # image folder\n",
    "        self.path_img = self.path/IMAGES\n",
    "            \n",
    "    def get_data(self):        \n",
    "        if self.valid_file: \n",
    "            self.train_valid_df = pd.concat([self.train_df, self.valid_df])\n",
    "            self.train_valid_df.columns = [\"images\"]\n",
    "            self.train_valid_df[\"is_valid\"] = len(self.train_df)*[False] + len(self.valid_df)*[True]\n",
    "        else:\n",
    "            self.train_valid_df = self.train_df\n",
    "        \n",
    "        # get\n",
    "        il = SegmentationItemList.from_df(self.train_valid_df, self.path_img) \n",
    "        # split\n",
    "        if self.valid_file: ill = il.split_from_df(\"is_valid\") \n",
    "        else: ill = il.split_by_rand_pct(ifnone(self.VALID, 0.2)) \n",
    "        # label\n",
    "        labels_dict = dict(zip(self.labels_df.iloc[:,0], self.labels_df.iloc[:,1]))\n",
    "        ll = ill.label_from_func(lambda o: labels_dict[Path(o).name], label_cls=self.label_cls)\n",
    "        # databunch    \n",
    "        data = (ll.transform(get_transforms(),\n",
    "                             size=self.size,\n",
    "                             tfm_y=False,\n",
    "                             resize_method=ResizeMethod.SQUISH)\n",
    "                    .databunch(bs=self.bs, **self.dl_kwargs))\n",
    "        # test\n",
    "        if self.TEST:\n",
    "            il = ImageList.from_df(self.test_df, self.path_img) # get\n",
    "            data.add_test(il, tfm_y=False)\n",
    "        return data\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"___repr__\"\"\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"___str___\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data creation - TODO: single label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (10054 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: MultiCategoryList\n",
       "1;3,3,0,3,0\n",
       "Path: /home/turgutluk/data/steel/strategy4/images;\n",
       "\n",
       "Valid: LabelList (2514 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: MultiCategoryList\n",
       "1,0,0,0,3\n",
       "Path: /home/turgutluk/data/steel/strategy4/images;\n",
       "\n",
       "Test: LabelList (1801 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /home/turgutluk/data/steel/strategy4/images"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data creation - multilabel\n",
    "PATH = Path(\"/home/turgutluk/data/steel/strategy4/\")\n",
    "IMAGES = \"images\"\n",
    "LABELS = \"labels_df.csv\"\n",
    "is_multilabel, sample_size, bs, size = True, None, 16, 224\n",
    "TRAIN, VALID, TEST = \"train_fold0.txt\", \"valid_fold0.txt\", \"test.txt\"\n",
    "ssdata = ImageClassificationData(PATH,IMAGES,LABELS,TRAIN,VALID,TEST,is_multilabel,sample_size,bs,size)\n",
    "data = ssdata.get_data(); data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_script.ipynb.\n",
      "Converted 02_scheduler.ipynb.\n",
      "Converted 03_callbacks.ipynb.\n",
      "Converted 04_optimizers_optimizers.ipynb.\n",
      "Converted 10_segmentation_dataset.ipynb.\n",
      "Converted 11_segmentation_losses_mulitlabel.ipynb.\n",
      "Converted 11b_segmentation_losses_binary.ipynb.\n",
      "Converted 12_segmentation_metrics.ipynb.\n",
      "Converted 13_segmentation_models.ipynb.\n",
      "Converted 14_segmentation_postprocess.ipynb.\n",
      "Converted 15_segmentation_tta.ipynb.\n",
      "Converted 16_segmentation_utils.ipynb.\n",
      "Converted 20_classification_dataset.ipynb.\n",
      "Converted segmentation_training.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
