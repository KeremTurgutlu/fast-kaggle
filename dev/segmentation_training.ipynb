{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script - do not run these cells \n",
    "\n",
    "relative imports fail when run as a script so scripts stays above library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.distributed import *\n",
    "from fastai.script import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from local.segmentation.dataset import *\n",
    "from local.segmentation.models import *\n",
    "from local.segmentation import metrics\n",
    "from local.segmentation import losses_binary, losses_multilabel\n",
    "from local.callbacks import *\n",
    "from local.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always keeps this in cell index position: 2\n",
    "from fastai.vision import *\n",
    "from fastai.distributed import *\n",
    "from fastai.script import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from local.segmentation.dataset import *\n",
    "from local.segmentation.models import *\n",
    "from local.segmentation import metrics\n",
    "from local.segmentation import losses_binary, losses_multilabel\n",
    "from local.callbacks import *\n",
    "from local.optimizers import *\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/8299270/ultimate-answer-to-relative-python-imports\n",
    "@call_parse\n",
    "def main(    \n",
    "    # data\n",
    "    PATH:Param(\"Path which have data\", str)=\"\",\n",
    "    IMAGES:Param(\"images folder path name\", str)=\"images\",\n",
    "    MASKS:Param(\"mask folder path name\", str)=\"masks\",\n",
    "    CODES:Param(\"codes.txt with pixel codes\", str)=\"\",\n",
    "    TRAIN:Param(\"train.txt with training image names\", str)=\"\",\n",
    "    VALID:Param(\"valid.txt with validation image names\", str)=None,\n",
    "    TEST:Param(\"test.txt with test image names\", str)=None,\n",
    "    suffix:Param(\"suffix for label filenames\", str)=\".png\",\n",
    "    sample_size:Param(\"\", int)=None,\n",
    "    bs:Param(\"Batch size\", int)=80,\n",
    "    size:Param(\"Image size\", str)=\"224\",\n",
    "    imagenet_pretrained:Param(\"Whether to normalize with inet stats\", int)=1,\n",
    "    \n",
    "    # model\n",
    "    modelname:Param(\"Model name from segmentation.models\", str)=\"resdunet18\",\n",
    "    modelconfig:Param(\"JSON dictionary of model config\", str)=\"{}\",\n",
    "    \n",
    "    # metric\n",
    "    tracking_metric:Param(\"Which metric to use for tracking and evaluation\", str)=\"dice\",\n",
    "    void_name:Param(\"Background class name\", str)=None,\n",
    "    \n",
    "    # train\n",
    "    loss_function:Param(\"Loss function for training\", str)=\"cross_entropy\",\n",
    "    opt:Param(\"Optimizer for training\", str)=None,\n",
    "    max_lr:Param(\"Learning Rate\", float)=3e-3,\n",
    "    epochs:Param(\"Number of max epochs to train\", int)=10,\n",
    "    \n",
    "    # modelexports\n",
    "    EXPORT_PATH:Param(\"Where to export trained model\", str)=\".\",\n",
    "    \n",
    "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    For Multi GPU Run: python ../fastai/fastai/launch.py {--gpus=0123} ./training.py {--your args}\n",
    "    For Single GPU Run: python ./training.py {--your args}\n",
    "    \"\"\"\n",
    "        \n",
    "    # Setup init\n",
    "    gpu = setup_distrib(gpu)\n",
    "    \n",
    "    # Args\n",
    "    if not gpu: print(f\"Print args here: \")\n",
    "        \n",
    "    # data\n",
    "    PATH = Path(PATH)\n",
    "    try: VALID = float(VALID)\n",
    "    except: passzx\n",
    "    size = eval(size)\n",
    "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN,\n",
    "                                      VALID, TEST, sample_size, bs, size, suffix)\n",
    "    data = ssdata.get_data()\n",
    "    if imagenet_pretrained: data.normalize(imagenet_stats)\n",
    "    else: data.normalize()   \n",
    "    \n",
    "    # model\n",
    "    model, split_fn, copy_conf = get_model(modelname, data, eval(modelconfig))\n",
    "    if not gpu: print(f\"Training with model: {modelname} and config: {copy_conf}\")\n",
    "        \n",
    "    # learn\n",
    "    learn = Learner(data, model)\n",
    "    learn = learn.split(split_fn)\n",
    "    pretrained = copy_conf[\"pretrained\"]\n",
    "    if pretrained: learn.freeze()\n",
    "    learn.path, learn.model_dir = Path(EXPORT_PATH), 'models'\n",
    "\n",
    "    # loss\n",
    "    try: loss = getattr(losses_binary, loss_function)\n",
    "    except: loss = getattr(losses_multilabel, loss_function)  \n",
    "    learn.loss_func = loss \n",
    "    if not gpu: print(f\"Training with loss: {learn.loss_func}\")\n",
    "        \n",
    "    # metric\n",
    "    metric = getattr(metrics, tracking_metric)\n",
    "    if not gpu: print(f\"Training with metric: {metric}\")\n",
    "    if tracking_metric in [\"multilabel_dice\", \"multilabel_iou\"]: metric = partial(metric, c=learn.data.c)\n",
    "    if tracking_metric == \"foreground_acc\": \n",
    "        void_code = np.where(learn.data.classes == void_name)[0].item()\n",
    "        metric = partial(metric, void_code=void_code)\n",
    "    learn.metrics = [metric]\n",
    "\n",
    "    # callbacks\n",
    "    save_cb = SaveDistributedModelCallback(learn, tracking_metric, \"max\", name=f\"best_of_{modelname}\", gpu=gpu)\n",
    "    csvlog_cb = CSVDistributedLogger(learn, 'training_log', append=True, gpu=gpu)\n",
    "    nan_cb = TerminateOnNaNCallback()\n",
    "    cbs = [save_cb, csvlog_cb, nan_cb]\n",
    "        \n",
    "    # optimizer / scheduler\n",
    "    alpha, mom, eps = 0.99, 0.9, 1e-8\n",
    "    if   opt=='adam':        opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='radam':       opt_func = partial(RAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='novograd':    opt_func = partial(Novograd, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rms':         opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n",
    "    elif opt=='sgd':         opt_func = partial(optim.SGD, momentum=mom)\n",
    "    elif opt=='ranger':      opt_func = partial(Ranger,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='ralamb':      opt_func = partial(Ralamb,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rangerlars':  opt_func = partial(RangerLars,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lookahead':   opt_func = partial(LookaheadAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lamb':        opt_func = partial(Lamb, betas=(mom,alpha), eps=eps)\n",
    "    if opt: learn.opt_func = opt_func\n",
    "\n",
    "    # distributed\n",
    "    if (gpu is not None) & (num_distrib()>1): learn.to_distributed(gpu)\n",
    "    \n",
    "    # to_fp16 \n",
    "    learn.to_fp16()\n",
    "    \n",
    "    # train\n",
    "    if not gpu: print(f\"Starting training with max_lr: {max_lr}\")\n",
    "    if imagenet_pretrained:\n",
    "        if not gpu: print(\"Training with transfer learning\")\n",
    "        # stage-1\n",
    "        learn.freeze_to(-1)\n",
    "        learn.fit_one_cycle(epochs, max_lr, callbacks=cbs)\n",
    "\n",
    "        # stage-2\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8, callbacks=cbs)\n",
    " \n",
    "        # stage-3\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8, callbacks=cbs)\n",
    "    else:\n",
    "        if not gpu: print(\"Training from scratch\")\n",
    "        learn.fit_one_cycle(epochs, max_lr, callbacks=cbs)\n",
    "        \n",
    "    # modelexports\n",
    "    if not nan_cb.isnan:\n",
    "        if TEST: dtypes = [\"Valid\", \"Test\"]\n",
    "        else: dtypes = [\"Valid\"]\n",
    "        for dtype in dtypes:\n",
    "            if not gpu: print(f\"Generating Raw Predictions for {dtype}...\")\n",
    "            ds_type = getattr(DatasetType, dtype)\n",
    "            preds, targs = learn.get_preds(ds_type)\n",
    "            ds = learn.data.test_ds if dtype == \"Test\" else learn.data.valid_ds\n",
    "            fnames = list(ds.items)\n",
    "            try_save({\"fnames\":fnames, \"preds\":to_cpu(preds), \"targs\":to_cpu(targs)},\n",
    "                     path=Path(EXPORT_PATH), file=f\"{dtype}_raw_preds.pkl\")\n",
    "            if not gpu: print(f\"Done.\")\n",
    "    else:\n",
    "        if not gpu: print(f\"Skipping Predictions due to NaN.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.export import *\n",
    "# xport script\n",
    "cells = read_nb(\"segmentation_training.ipynb\")['cells']\n",
    "src = cells[2]['source']\n",
    "with open(\"segmentation_training.py\", \"w\") as f: f.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `segmentation_training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from local.script import run_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "Print args here:\n",
      "Training with model: deeplabv3res50 and config: {'pretrained': True, 'variant': 'D', 'skip': 'm1', 'skip_num': 48}\n",
      "Training with metric: <function foreground_acc at 0x7f4d6ef917b8>\n",
      "Training with loss: FlattenedLoss of CrossEntropyLoss()\n",
      "Starting training with max_lr: 0.003\n",
      "Training with transfer learning\n",
      "epoch     train_loss  valid_loss  foreground_acc  time\n",
      "Initializing self.best\n"
     ]
    }
   ],
   "source": [
    "rc = run_command(f\"\"\"\n",
    "python segmentation_training.py \\\n",
    "--PATH=/home/turgutluk/.fastai/data/camvid \\\n",
    "--IMAGES=images \\\n",
    "--MASKS=labels \\\n",
    "--CODES=codes.txt \\\n",
    "--TRAIN=train.txt \\\n",
    "--VALID=0.2 \\\n",
    "--TEST=test.txt \\\n",
    "--bs=4 \\\n",
    "--size=(112,112) \\\n",
    "--imagenet_pretrained=1 \\\n",
    "--modelname=deeplabv3res50 \\\n",
    "--modelconfig=\"dict()\" \\\n",
    "--tracking_metric=foreground_acc \\\n",
    "--void_name=Void \\\n",
    "--loss_function=cross_entropy \\\n",
    "--opt=radam \\\n",
    "--max_lr=3e-3 \\\n",
    "--epochs=10 \\\n",
    "--EXPORT_PATH=./experiment_export\n",
    "\"\"\", logfn=\"./experiment_export/stdouterr.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rc = run_command(f\"\"\"\n",
    "# python {Path(fastai.__file__).parent}/launch.py \n",
    "# --gpus=01 segmentation_training.py \\\n",
    "# --PATH=/home/turgutluk/.fastai/data/camvid \\\n",
    "# --IMAGES=images \\\n",
    "# --MASKS=labels \\\n",
    "# --CODES=codes.txt \\\n",
    "# --TRAIN=train.txt \\\n",
    "# --VALID=0.2 \\\n",
    "# --TEST=test.txt \\\n",
    "# --bs=4 \\\n",
    "# --size=112 \\\n",
    "# --imagenet_pretrained=1 \\\n",
    "# --modelname=resdunet18 \\\n",
    "# --modelconfig=\"dict()\" \\\n",
    "# --tracking_metric=\"dice\" \\\n",
    "# --void_name=None \\\n",
    "# --loss_function=\"cross_entropy\" \\\n",
    "# --opt=radam \\\n",
    "# --max_lr=3e-3 \\\n",
    "# --epochs=10 \\\n",
    "# --EXPORT_PATH=\".\"\n",
    "# \"\"\", logfn=\"./experiment_export/stdouterr.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_PATH = Path(\"./experiment_export/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = json.loads(open(EXPORT_PATH/\"stdouterr.log\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time, cmd, stderr, stdout =  logs[-1].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/01/2019, 22:45:24'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('experiment_export/training_log.csv'),\n",
       " PosixPath('experiment_export/models'),\n",
       " PosixPath('experiment_export/stdouterr.log')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPORT_PATH.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    valid_preds = torch.load(EXPORT_PATH/'Valid_raw_preds.pkl')\n",
    "    valid_preds['targs'][0]\n",
    "except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
