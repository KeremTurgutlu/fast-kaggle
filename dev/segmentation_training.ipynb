{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script - do not run these cells \n",
    "\n",
    "relative imports fail when run as a script so scripts stays above library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.distributed import *\n",
    "from fastai.script import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from local.segmentation.dataset import *\n",
    "from local.segmentation import metrics\n",
    "from local.segmentation import losses\n",
    "from local.callbacks import *\n",
    "from local.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always keeps this in cell index position: 2\n",
    "from fastai.vision import *\n",
    "from fastai.distributed import *\n",
    "from fastai.script import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from local.segmentation.dataset import *\n",
    "from local.segmentation import metrics\n",
    "from local.segmentation import losses\n",
    "from local.callbacks import *\n",
    "from local.optimizers import *\n",
    "\n",
    "# https://stackoverflow.com/questions/8299270/ultimate-answer-to-relative-python-imports\n",
    "@call_parse\n",
    "def main(    \n",
    "    PATH:Param(\"Path which have data\", str)=\"\",\n",
    "    IMAGES:Param(\"images folder path name\", str)=\"images\",\n",
    "    MASKS:Param(\"mask folder path name\", str)=\"masks\",\n",
    "    CODES:Param(\"codes.txt with pixel codes\", str)=\"\",\n",
    "    TRAIN:Param(\"train.txt with training image names\", str)=\"\",\n",
    "    VALID:Param(\"valid.txt with validation image names\", str)=None,\n",
    "    TEST:Param(\"test.txt with test image names\", str)=None,\n",
    "    sample_size:Param(\"\", int)=None,\n",
    "    bs:Param(\"Batch size\", int)=80,\n",
    "    size:Param(\"Image size\", int)=224,\n",
    "    imagenet_pretrained:Param(\"Use imagenet weights for DynamicUnet\", int)=1,\n",
    "    max_lr:Param(\"Learning Rate\", float)=3e-3,\n",
    "    model_name:Param(\"Model name for save\", str)=\"mybestmodel\",\n",
    "    epochs:Param(\"Number of max epochs to train\", int)=10,\n",
    "    tracking_metric:Param(\"Which metric to use for tracking and evaluation\", str)=\"dice\",\n",
    "    void_name:Param(\"Background class name\", str)=None,\n",
    "    loss_function:Param(\"Loss function for training\", str)=\"crossentropy\",\n",
    "    opt:Param(\"Optimizer for training\", str)=None,\n",
    "    arch_name:Param(\"Architecture backbone for training\", str)=\"resnet34\",\n",
    "    EXPORT_PATH:Param(\"Where to export trained model\", str)=\".\",\n",
    "    \n",
    "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    For Multi GPU Run: python ../fastai/fastai/launch.py {--gpus=0123} ./training.py {--your args}\n",
    "    For Single GPU Run: python ./training.py {--your args}\n",
    "    bs: 80 size: 224 , bs: 320 size: 112 \n",
    "    \"\"\"\n",
    "        \n",
    "    # Setup init\n",
    "    gpu = setup_distrib(gpu)\n",
    "    \n",
    "    # Args\n",
    "    if not gpu: print(f\"Print args here: \")\n",
    "        \n",
    "    # Get data\n",
    "    PATH = Path(PATH)\n",
    "    try: VALID = float(VALID)\n",
    "    except: pass\n",
    "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
    "    data = ssdata.get_data()\n",
    "    if imagenet_pretrained: data.normalize(imagenet_stats)\n",
    "    else: data.normalize()   \n",
    "    \n",
    "    # learn - models: 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50',\n",
    "    arch = getattr(models, arch_name)\n",
    "    if not gpu: print(f\"Training with arch: {arch}\")\n",
    "    learn = unet_learner(data, arch = arch, pretrained = True)\n",
    "    learn.path, learn.model_dir = Path(EXPORT_PATH), 'models'\n",
    "\n",
    "    # metric\n",
    "    metric = getattr(metrics, tracking_metric)\n",
    "    if not gpu: print(f\"Tracking metric: {metric}\")\n",
    "    if tracking_metric in [\"multilabel_dice\", \"multilabel_iou\"]: metric = partial(metric, c=learn.data.c)\n",
    "    if tracking_metric == \"foreground_acc\": \n",
    "        void_code = np.where(learn.data.classes == void_name)[0].item()\n",
    "        metric = partial(metric, void_code=void_code)\n",
    "    learn.metrics = [metric]\n",
    "    \n",
    "    # loss\n",
    "    loss = getattr(losses, loss_function, None)\n",
    "    if loss: learn.loss_func = loss \n",
    "    if not gpu: print(f\"Training with loss: {learn.loss_func}\")\n",
    "\n",
    "    # callbacks\n",
    "    save_cb = SaveDistributedModelCallback(learn, tracking_metric, \"max\", name=model_name, gpu=gpu)\n",
    "    csvlog_cb = CSVDistributedLogger(learn, 'training_log', append=True, gpu=gpu)\n",
    "    cbs = [save_cb, csvlog_cb]\n",
    "        \n",
    "    # optimizer / scheduler\n",
    "    alpha=0.99; mom=0.9; eps=1e-8\n",
    "    \n",
    "    if   opt=='adam':        opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='radam':       opt_func = partial(RAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='novograd':    opt_func = partial(Novograd, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rms':         opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n",
    "    elif opt=='sgd':         opt_func = partial(optim.SGD, momentum=mom)\n",
    "    elif opt=='ranger':      opt_func = partial(Ranger,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='ralamb':      opt_func = partial(Ralamb,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rangerlars':  opt_func = partial(RangerLars,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lookahead':   opt_func = partial(LookaheadAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lamb':        opt_func = partial(Lamb, betas=(mom,alpha), eps=eps)\n",
    "    \n",
    "    if opt: learn.opt_func = opt_func\n",
    "\n",
    "    # distributed\n",
    "    if (gpu is not None) & (num_distrib()>1): learn.to_distributed(gpu)\n",
    "    \n",
    "    # to_fp16 \n",
    "    learn.to_fp16()\n",
    "    \n",
    "    # train\n",
    "    if not gpu: print(f\"Starting training with max_lr: {max_lr}\")\n",
    "    if imagenet_pretrained:\n",
    "        if not gpu: print(\"Training with transfer learning\")\n",
    "        # stage-1\n",
    "        learn.freeze_to(-1)\n",
    "        learn.fit_one_cycle(epochs, max_lr, callbacks=cbs)\n",
    "\n",
    "        # stage-2\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8, callbacks=cbs)\n",
    " \n",
    "        # stage-3\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8, callbacks=cbs)\n",
    "    else:\n",
    "        if not gpu: print(\"Training from scratch\")\n",
    "        learn.fit_one_cycle(epochs, max_lr, callbacks=cbs)\n",
    "        \n",
    "    # save valid and test preds \n",
    "    if TEST: dtypes = [\"Valid\", \"Test\"]\n",
    "    else: dtypes = [\"Valid\"]\n",
    "    for dtype in dtypes:\n",
    "        if not gpu: print(f\"Generating Raw Predictions for {dtype}...\")\n",
    "        preds, targs = learn.get_preds(getattr(DatasetType, dtype))\n",
    "        fnames = list(data.test_ds.items)\n",
    "        try_save({\"fnames\":fnames, \"preds\":to_cpu(preds), \"targs\":to_cpu(targs)},\n",
    "                 path=Path(EXPORT_PATH), file=f\"{dtype}_raw_preds.pkl\")\n",
    "\n",
    "    # to_fp32 + export learn\n",
    "    learn.to_fp32()    \n",
    "    learn.load(model_name) # load best saved model\n",
    "    if not gpu: print(f\"Exporting model to: {EXPORT_PATH}\")\n",
    "    learn.export(f\"{model_name}_export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.export import *\n",
    "# export script\n",
    "cells = read_nb(\"segmentation_training.ipynb\")['cells']\n",
    "src = cells[2]['source']\n",
    "with open(\"segmentation_training.py\", \"w\") as f: f.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `run_command`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from local.script import run_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "Print args here:\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc = run_command(f\"\"\"\n",
    "python {Path(fastai.__file__).parent}/launch.py \n",
    "--gpus=0123 segmentation_training.py \\\n",
    "--PATH=/home/turgutluk/.fastai/data/camvid \\\n",
    "--IMAGES=images \\\n",
    "--MASKS=labels \\\n",
    "--CODES=codes.txt \\\n",
    "--TRAIN=dasd.txt \\\n",
    "--VALID=0.2 \\\n",
    "--TEST=test.txt \\\n",
    "--bs=4 \\\n",
    "--size=112 \\\n",
    "--imagenet_pretrained=1 \\\n",
    "--max_lr=3e-3 \\\n",
    "--model_name=mybestmodel \\\n",
    "--epochs=1 \\\n",
    "--tracking_metric=foreground_acc \\\n",
    "--void_name=Void \\\n",
    "--loss_function=xentropy \\\n",
    "--opt=radam\n",
    "--EXPORT_PATH=./experiment_export\n",
    "\"\"\", stderr_fn=\"./experiment_export/stdouterr.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "APPENDED NEW LOG at: 09/17/2019, 20:56:49\n",
      "COMMAND: ['python', '/home/turgutluk/fastai/fastai/launch.py', '--gpus=0123', 'segmentation_training.py', '--PATH=/home/turgutluk/.fastai/data/camvid', '--IMAGES=images', '--MASKS=labels', '--CODES=codes.txt', '--TRAIN=dasd.txt', '--VALID=0.2', '--TEST=test.txt', '--bs=4', '--size=112', '--imagenet_pretrained=1', '--max_lr=3e-3', '--model_name=mybestmodel', '--epochs=1', '--tracking_metric=foreground_acc', '--void_name=Void', '--loss_function=xentropy', '--opt=radam', '--EXPORT_PATH=./experiment_export']\n",
      "STDERR: Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"segmentation_training.py\", line 37, in <module>\n",
      "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
      "  File \"/home/turgutluk/fastai/fastai/script.py\", line 40, in call_parse\n",
      "    func(**args.__dict__)\n",
      "  File \"segmentation_training.py\", line 55, in main\n",
      "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
      "  File \"/home/turgutluk/git/fast-kaggle/dev/local/segmentation/dataset.py\", line 18, in __init__\n",
      "    self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 702, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 429, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 895, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1122, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1853, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 387, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 705, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: [Errno 2] File b'/home/turgutluk/.fastai/data/camvid/dasd.txt' does not exist: b'/home/turgutluk/.fastai/data/camvid/dasd.txt'\n",
      "\n",
      "STDOUT: To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "Print args here: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(\"./experiment_export/stdouterr.log\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
