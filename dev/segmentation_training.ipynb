{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script - do not run these cells \n",
    "\n",
    "relative imports fail when run as a script so scripts stays above library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always keeps this in cell index position: 1\n",
    "from fastai.vision import *\n",
    "from fastai.distributed import *\n",
    "from fastai.script import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from local.segmentation.dataset import *\n",
    "from local.segmentation import metrics\n",
    "from local.segmentation import losses\n",
    "from local.distributed import *\n",
    "from local.optimizers import *\n",
    "\n",
    "# https://stackoverflow.com/questions/8299270/ultimate-answer-to-relative-python-imports\n",
    "@call_parse\n",
    "def main(    \n",
    "    PATH:Param(\"Path which have data\", str)=\"\",\n",
    "    IMAGES:Param(\"images folder path name\", str)=\"images\",\n",
    "    MASKS:Param(\"mask folder path name\", str)=\"masks\",\n",
    "    CODES:Param(\"codes.txt with pixel codes\", str)=\"\",\n",
    "    TRAIN:Param(\"train.txt with training image names\", str)=\"\",\n",
    "    VALID:Param(\"valid.txt with validation image names\", str)=None,\n",
    "    TEST:Param(\"test.txt with test image names\", str)=None,\n",
    "    sample_size:Param(\"\", int)=None,\n",
    "    bs:Param(\"Batch size\", int)=80,\n",
    "    size:Param(\"Image size\", int)=224,\n",
    "    imagenet_pretrained:Param(\"Use imagenet weights for DynamicUnet\", int)=1,\n",
    "    max_lr:Param(\"Learning Rate\", float)=3e-3,\n",
    "    model_name:Param(\"Model name for save\", str)=\"mybestmodel\",\n",
    "    epochs:Param(\"\"\"Number of max epochs to train\"\"\", int)=10,\n",
    "    tracking_metric:Param(\"\"\"Which metric to use for tracking and evaluation\"\"\", str)=\"dice\",\n",
    "    void_name:Param(\"\"\"Background class name\"\"\", str)=None,\n",
    "    loss_function:Param(\"\"\"Loss function for training\"\"\", str)=\"crossentropy\",\n",
    "    opt:Param(\"\"\"Optimizer for training\"\"\", str)=None,\n",
    "    arch_name:Param(\"\"\"Architecture backbone for training\"\"\", str)=\"resnet34\",\n",
    "    \n",
    "    EXPORT_PATH:Param(\"\"\"Where to export trained model\"\"\", str)=\".\",\n",
    "    \n",
    "    gpu:Param(\"GPU to run on, can handle multi gpu\", str)=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    For Multi GPU Run: python ../fastai/fastai/launch.py {--gpus=0123} ./training.py {--your args}\n",
    "    For Single GPU Run: python ./training.py {--your args}\n",
    "    bs: 80 size: 224 , bs: 320 size: 112 \n",
    "    \"\"\"\n",
    "        \n",
    "    # Setup init\n",
    "    gpu = setup_distrib(gpu)\n",
    "    \n",
    "    # Args\n",
    "    if not gpu: print(f\"Print args here: \")\n",
    "        \n",
    "    # Get data\n",
    "    PATH = Path(PATH)\n",
    "    ssdata = SemanticSegmentationData(PATH, IMAGES, MASKS, CODES, TRAIN, VALID, TEST, sample_size, bs, size)\n",
    "    data = ssdata.get_data()\n",
    "    if imagenet_pretrained: data.normalize(imagenet_stats)\n",
    "    else: data.normalize()   \n",
    "    \n",
    "    # learn - models: 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50',\n",
    "    arch = getattr(models, arch_name)\n",
    "    if not gpu: print(f\"Training with arch: {arch}\")\n",
    "    learn = unet_learner(data, arch = arch, pretrained = True)\n",
    "    learn.path, learn.model_dir = Path(EXPORT_PATH), 'models'\n",
    "\n",
    "    # metric\n",
    "    metric = getattr(metrics, tracking_metric)\n",
    "    if not gpu: print(f\"Tracking metric: {metric}\")\n",
    "    if tracking_metric in [\"multilabel_dice\", \"multilabel_iou\"]: metric = partial(metric, c=learn.data.c)\n",
    "    if tracking_metric == \"foreground_acc\": \n",
    "        void_code = np.where(learn.data.classes == void_name)[0].item()\n",
    "        metric = partial(metric, void_code=void_code)\n",
    "    learn.metrics = [metric]\n",
    "    \n",
    "    # loss\n",
    "    loss = getattr(losses, loss_function, None)\n",
    "    if loss: learn.loss_func = loss \n",
    "    if not gpu: print(f\"Training with loss: {learn.loss_func}\")\n",
    "\n",
    "    # callbacks\n",
    "    learn.callback_fns.append(partial(SaveDistributedModelCallback, monitor=tracking_metric, \n",
    "                                      mode=\"max\", name=model_name, gpu=gpu))\n",
    "        \n",
    "    # optimizer / scheduler\n",
    "    alpha=0.99; mom=0.9; eps=1e-8\n",
    "    \n",
    "    if   opt=='adam' : opt_func = partial(optim.Adam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='radam' : opt_func = partial(RAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='novograd' : opt_func = partial(Novograd, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rms'  : opt_func = partial(optim.RMSprop, alpha=alpha, eps=eps)\n",
    "    elif opt=='sgd'  : opt_func = partial(optim.SGD, momentum=mom)\n",
    "    elif opt=='ranger'  : opt_func = partial(Ranger,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='ralamb'  : opt_func = partial(Ralamb,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='rangerlars'  : opt_func = partial(RangerLars,  betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lookahead'  : opt_func = partial(LookaheadAdam, betas=(mom,alpha), eps=eps)\n",
    "    elif opt=='lamb'  : opt_func = partial(Lamb, betas=(mom,alpha), eps=eps)\n",
    "    if opt: learn.opt_func = opt_func\n",
    "\n",
    "    # distributed\n",
    "    if (gpu is not None) & (num_distrib()>1): learn.to_distributed(gpu)\n",
    "    \n",
    "    # to_fp16 \n",
    "    learn.to_fp16()\n",
    "    \n",
    "    # train\n",
    "    if not gpu: print(f\"Starting training with max_lr: {max_lr}\")\n",
    "    if imagenet_pretrained:\n",
    "        if not gpu: print(\"Training with transfer learning\")\n",
    "        # stage-1\n",
    "        learn.freeze_to(-1)\n",
    "        learn.fit_one_cycle(epochs, max_lr)\n",
    "        \n",
    "        # load model hack\n",
    "        best_init = learn.save_model_callback.best\n",
    "        learn.callback_fns = [cb_fn for cb_fn in learn.callback_fns if cb_fn.func == Recorder]\n",
    "        learn.callback_fns.append(partial(SaveDistributedModelCallback, monitor=tracking_metric, name=model_name, best_init=best_init))\n",
    "\n",
    "        # stage-2\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8)\n",
    "        \n",
    "        # load model hack\n",
    "        best_init = learn.save_model_callback.best\n",
    "        learn.callback_fns = [cb_fn for cb_fn in learn.callback_fns if cb_fn.func == Recorder]\n",
    "        learn.callback_fns.append(partial(SaveDistributedModelCallback, monitor=tracking_metric, name=model_name, best_init=best_init))\n",
    "\n",
    "        # stage-3\n",
    "        lrs = slice(max_lr/100,max_lr/4)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, lrs, pct_start=0.8)\n",
    "    else:\n",
    "        if not gpu: print(\"Training from scratch\")\n",
    "        learn.fit_one_cycle(epochs, max_lr)\n",
    "    \n",
    "        \n",
    "    # save test preds \n",
    "    if TEST:\n",
    "        preds, targs = learn.get_preds(DatasetType.Test)\n",
    "        fnames = list(data.test_ds.items)\n",
    "        try_save({\"fnames\":fnames, \n",
    "                  \"preds\":to_cpu(preds),\n",
    "                  \"targs\":to_cpu(targs)}, path=Path(EXPORT_PATH), file=\"raw_preds.pkl\")\n",
    "    \n",
    "    # to_fp32 + export learn\n",
    "    learn.to_fp32()    \n",
    "    learn.load(model_name) # load best saved model\n",
    "    if not gpu: print(f\"Exporting model to: {EXPORT_PATH}\")\n",
    "    learn.export(f\"{model_name}_export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.export import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export script\n",
    "src = read_nb(\"segmentation_training.ipynb\")['cells'][1]['source']\n",
    "with open(\"segmentation_training.py\", \"w\") as f: f.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n",
      "Print args here:\n",
      "Training with arch: <function resnet34 at 0x7f86db72d7b8>\n",
      "Tracking metric: <function foreground_acc at 0x7f86dbd41b70>\n",
      "Training with loss: FlattenedLoss of CrossEntropyLoss()\n",
      "Starting training with max_lr: 0.003\n",
      "Training with transfer learning\n",
      "epoch     train_loss  valid_loss  foreground_acc  time\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "\n",
    "from local.script import run_command\n",
    "run_command(f\"\"\"\n",
    "python {Path(fastai.__file__).parent}/launch.py \n",
    "--gpus=0123 segmentation_training.py \\\n",
    "--PATH=/home/turgutluk/.fastai/data/camvid \\\n",
    "--IMAGES=images \\\n",
    "--MASKS=labels \\\n",
    "--CODES=codes.txt \\\n",
    "--TRAIN=train.txt \\\n",
    "--VALID=valid.txt \\\n",
    "--TEST=test.txt \\\n",
    "--bs=4 \\\n",
    "--size=112 \\\n",
    "--imagenet_pretrained=1 \\\n",
    "--max_lr=3e-3 \\\n",
    "--model_name=mybestmodel \\\n",
    "--epochs=20 \\\n",
    "--tracking_metric=foreground_acc \\\n",
    "--void_name=Void \\\n",
    "--loss_function=xentropy \\\n",
    "--opt=radam\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
