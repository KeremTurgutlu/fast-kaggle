{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.57'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_data(URLs.CAMVID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = Path('/root/.fastai/data/camvid')\n",
    "\n",
    "# image_files = get_files(PATH/\"images\")\n",
    "\n",
    "# image_file_names = [o.stem for o in image_files]\n",
    "\n",
    "# image_file_names[:2]\n",
    "\n",
    "# # make image names and mask names same\n",
    "# for name in image_file_names:\n",
    "#     shutil.copy(PATH/f\"masks/{name}_P.png\", PATH/f\"masks/{name}.png\")\n",
    "\n",
    "# len(image_file_names)\n",
    "\n",
    "# test_image_names = list(pd.read_csv(PATH/\"test.txt\", header=None)[0])\n",
    "\n",
    "# train_image_names = [f\"{name}.png\" for name in image_file_names if f\"{name}.png\" not in test_image_names]\n",
    "\n",
    "# pd.DataFrame(train_image_names).to_csv(PATH/\"train.txt\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_files = get_files(PATH/'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = open_image(image_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to USER SPACE\n",
    "# shutil.copytree(PATH, Path(os.environ[\"SENSEI_USERSPACE_SELF\"])/\"camvid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERSPACE = Path(os.environ[\"SENSEI_USERSPACE_SELF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SemanticSegmentationData:\n",
    "    \"\"\"\n",
    "    Creates semantic segmentation data,masks should be already numericalized.\n",
    "    Normalization is not done here, can be different in different TL settings.\n",
    "    Test set is always assumed to be without labels, otherwise use valid.\n",
    "    \"\"\"\n",
    "    def __init__(self, PATH, CODES, TRAIN, VALID, TEST, sample_size, bs, size, has_test_labels=True):\n",
    "        \"\"\"\n",
    "        path: path to data folder\n",
    "        codes: txt file which has segmentation pixel codes\n",
    "        sample_size: training sample size, None for all\n",
    "        bs: batch size\n",
    "        size: image size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path, self.sample_size, self.bs, self.size, self.has_test_labels  =\\\n",
    "                                            PATH, sample_size, bs, size, has_test_labels\n",
    "        self.codes = np.loadtxt(self.path/CODES, dtype=str)\n",
    "        \n",
    "        self.train_df = pd.read_csv(self.path/TRAIN, header=None)\n",
    "        if VALID is not None: self.valid_df = pd.read_csv(self.path/VALID, header=None)\n",
    "        if TEST is not None: self.test_df = pd.read_csv(self.path/TEST, header=None)\n",
    "        \n",
    "        self.path_img = self.path/\"images\"\n",
    "        self.path_lbl = self.path/\"masks\"\n",
    "        \n",
    "        self.VALID, self.TEST = VALID, TEST\n",
    "        \n",
    "    def get_y_fn(self, x): return self.path_lbl/f'{Path(x).stem}.png'\n",
    "        \n",
    "    def get_data(self):        \n",
    "        if self.VALID: \n",
    "            self.train_valid_df = pd.concat([self.train_df, self.valid_df])\n",
    "            self.train_valid_df.columns = [\"images\"]\n",
    "            self.train_valid_df[\"is_valid\"] = len(self.train_df)*[False] + len(self.valid_df)*[True]\n",
    "        else:\n",
    "            self.train_valid_df = self.train_df\n",
    "        \n",
    "        il = SegmentationItemList.from_df(self.train_valid_df, self.path, folder=\"images\") # get\n",
    "        if self.VALID: ill = il.split_from_df(\"is_valid\") # split\n",
    "        else: ill = il.split_by_rand_pct() # split\n",
    "        ll = ill.label_from_func(self.get_y_fn, classes=self.codes) # label\n",
    "            \n",
    "        data = (ll.transform(get_transforms(), size=(self.size, self.size), tfm_y=True,\n",
    "                             resize_method=ResizeMethod.SQUISH)\n",
    "                    .databunch(bs=self.bs))\n",
    "        \n",
    "        # add_test\n",
    "        if self.TEST:\n",
    "            il = SegmentationItemList.from_df(self.test_df, self.path, folder=\"images\") # get\n",
    "            data.add_test(il, tfm_y=False)\n",
    "        return data\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"___repr__\"\"\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"___str___\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel: CAMVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom validation\n",
    "PATH, CODES, TRAIN, VALID, TEST = Path(USERSPACE/'camvid'), \"codes.txt\", \"train.txt\", \"valid.txt\", \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, CODES, TRAIN, VALID, TEST, sample_size=None, bs=4, size=112)\n",
    "data = ssdata.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (600 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid;\n",
       "\n",
       "Valid: LabelList (101 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid;\n",
       "\n",
       "Test: LabelList (101 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07959.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07961.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07963.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07965.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07967.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07969.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07971.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07973.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07975.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07977.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07979.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07981.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07983.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07985.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07987.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07989.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07991.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07993.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07995.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07997.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_07999.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08001.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08003.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08005.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08007.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08009.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08011.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08013.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08015.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08017.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08019.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08021.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08023.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08025.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08027.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08029.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08031.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08033.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08035.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08037.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08039.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08041.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08043.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08045.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08047.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08049.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08051.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08053.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08055.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08057.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08059.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08061.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08063.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08065.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08067.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08069.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08071.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08073.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08075.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08077.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08079.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08081.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08083.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08085.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08087.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08089.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08091.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08093.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08095.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08097.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08099.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08101.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08103.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08105.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08107.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08109.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08111.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08113.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08115.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08117.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08119.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08121.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08123.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08125.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08127.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08129.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08131.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08133.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08135.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08137.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08139.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08141.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08143.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08145.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08147.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08149.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08151.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08153.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08155.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08157.png',\n",
       " '/trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid/images/0016E5_08159.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.test_ds.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random validation\n",
    "PATH, CODES, TRAIN, VALID, TEST = Path(USERSPACE/'camvid'), \"codes.txt\", \"train.txt\", None, \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, CODES, TRAIN, VALID, TEST, sample_size=None, bs=4, size=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (480 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid;\n",
       "\n",
       "Valid: LabelList (120 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid;\n",
       "\n",
       "Test: LabelList (101 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/camvid"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ssdata.get_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary: SIIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom validation\n",
    "PATH, CODES, TRAIN, VALID, TEST = Path(USERSPACE/'siim'), \"codes.txt\", \"train.txt\", None, \"test.txt\"\n",
    "ssdata = SemanticSegmentationData(PATH, CODES, TRAIN, VALID, TEST, sample_size=None, bs=4, size=112, has_test_labels=False)\n",
    "data = ssdata.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (9638 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/siim;\n",
       "\n",
       "Valid: LabelList (2409 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: SegmentationLabelList\n",
       "ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112),ImageSegment (1, 112, 112)\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/siim;\n",
       "\n",
       "Test: LabelList (3205 items)\n",
       "x: SegmentationItemList\n",
       "Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112),Image (3, 112, 112)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /trainman-mount/trainman-storage-ac168968-e641-4146-85da-cf960ab9e0bc/siim"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix SIIM masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_files = get_files(PATH/\"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in mask_files:\n",
    "#     mask = open_mask(fname)\n",
    "#     pixel_vals = mask.data.unique()\n",
    "#     if len(pixel_vals) == 1: assert pixel_vals.item() == 0\n",
    "#     elif len(pixel_vals) == 2: assert torch.equal(pixel_vals, tensor([1,0]))\n",
    "#     else: \n",
    "#         mask = open_mask(fname, div=True)\n",
    "#         pixel_vals = mask.data.unique()\n",
    "#         assert torch.equal(pixel_vals, tensor([1,0]))\n",
    "#         PIL.Image.fromarray(image2np(mask.data).astype(np.uint8)).save(PATH/\"masks\"/f\"{fname}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in mask_files:\n",
    "#     mask = open_mask(fname)\n",
    "#     pixel_vals = mask.data.unique()\n",
    "#     if len(pixel_vals) == 1: assert pixel_vals.item() == 0\n",
    "#     elif len(pixel_vals) == 2: assert torch.equal(pixel_vals, tensor([1,0]))\n",
    "#     else: assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
